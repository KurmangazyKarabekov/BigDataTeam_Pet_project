{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df2d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter vacancy name:\n",
      "учитель\n",
      "403 Forbidden for page 37. Retrying...\n",
      "403 Forbidden for page 37. Retrying...\n",
      "403 Forbidden for page 117. Retrying...\n",
      "403 Forbidden for page 117. Retrying...\n",
      "Successfully saved 1375 vacancies to учитель.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_max_vacancies(search_term):\n",
    "    url = 'https://api.hh.ru/vacancies'\n",
    "    params = {\n",
    "        'text': search_term,\n",
    "        'area': '40',  # area 40 == Kazakhstan\n",
    "        'per_page': '1',  # Only need to get one item to find the total count\n",
    "        'page': 0\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # Raise an exception if the request failed\n",
    "    return response.json()['found']  # Total number of vacancies found\n",
    "\n",
    "def get_raw_vacancies(search_term, amount):\n",
    "    raw_vacancies_data = []\n",
    "    url = 'https://api.hh.ru/vacancies'\n",
    "    \n",
    "    total_pages = (amount // 10) + (1 if amount % 10 > 0 else 0)  # Calculate total pages to fetch\n",
    "\n",
    "    for page in range(total_pages):\n",
    "        params = {\n",
    "            'text': search_term,\n",
    "            'area': '40',  # area 40 == Kazakhstan\n",
    "            'per_page': '10',\n",
    "            'page': page\n",
    "        }\n",
    "\n",
    "        # Retry mechanism\n",
    "        retries = 3\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(url, params=params)\n",
    "                response.raise_for_status()  # Raise an exception if the request failed\n",
    "                raw_vacancies_data.append(response.json())\n",
    "                break  # Exit the retry loop if successful\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if e.response.status_code == 403:\n",
    "                    print(f\"403 Forbidden for page {page}. Retrying...\")\n",
    "                    time.sleep(5)  # Wait before retrying\n",
    "                else:\n",
    "                    print(f\"HTTP error occurred: {e}\")\n",
    "                    return []  # Return empty list on other errors\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return []\n",
    "\n",
    "    return raw_vacancies_data\n",
    "\n",
    "def extract_salary(vacancy):\n",
    "    if vacancy['salary'] is not None:\n",
    "        salary_from = vacancy['salary']['from']\n",
    "        salary_to = vacancy['salary']['to']\n",
    "    else:\n",
    "        salary_from = None\n",
    "        salary_to = None\n",
    "    return salary_from, salary_to\n",
    "\n",
    "def extract_address(vacancy):\n",
    "    if vacancy['address'] is not None:\n",
    "        address_raw = vacancy['address']['raw']\n",
    "    else:\n",
    "        address_raw = None\n",
    "    return address_raw\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    columns = [\n",
    "        'Job Title',\n",
    "        'Company Name',\n",
    "        'Salary From',\n",
    "        'Salary To',\n",
    "        'Region',\n",
    "        'Full Address',\n",
    "        'Apply URL',\n",
    "        'Vacancy URL',\n",
    "        'Publication Time',\n",
    "        'Archived',\n",
    "        'Requirements',\n",
    "        'Responsibilities'\n",
    "    ]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.to_csv(filename, index=True, encoding='utf-8')\n",
    "\n",
    "def extract_information(search_term):\n",
    "    clear_data = []\n",
    "    amount = get_max_vacancies(search_term)\n",
    "\n",
    "    for elem in get_raw_vacancies(search_term, amount):\n",
    "        page = elem['items']\n",
    "        for vacancy in page:\n",
    "            salary_from, salary_to = extract_salary(vacancy)\n",
    "            address_raw = extract_address(vacancy)\n",
    "\n",
    "            clear_data.append([\n",
    "                vacancy['name'],\n",
    "                vacancy['employer']['name'],\n",
    "                salary_from,\n",
    "                salary_to,\n",
    "                vacancy['area']['name'],\n",
    "                address_raw,\n",
    "                vacancy['apply_alternate_url'],\n",
    "                vacancy['alternate_url'],\n",
    "                vacancy['published_at'],\n",
    "                vacancy['archived'],\n",
    "                vacancy['snippet']['requirement'],\n",
    "                vacancy['snippet']['responsibility']\n",
    "            ])\n",
    "\n",
    "    return clear_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Please enter vacancy name:')\n",
    "    search_term = input().strip()\n",
    "    extracted_data = extract_information(search_term)\n",
    "\n",
    "    filename = f'{search_term}.csv'\n",
    "    save_to_csv(extracted_data, filename)\n",
    "    print(f'Successfully saved {len(extracted_data)} vacancies to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a242b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
